{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "listed-finder",
   "metadata": {},
   "source": [
    "## Content\n",
    "The datasets consists of several medical predictor variables and one target variable, **Outcome**. Predictor variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.\n",
    "\n",
    "## Context\n",
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tamil-delight",
   "metadata": {},
   "source": [
    "## Inspiration\n",
    "Can you build a machine learning model to accurately predict whether or not the patients in the dataset have diabetes or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info(), data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-tanzania",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Outcome.value_counts().plot(kind=\"bar\", color=['salmon','lightblue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-master",
   "metadata": {},
   "source": [
    "## Age Distribution of the age column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 5))\n",
    "ax.hist(data.Age.value_counts(), bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-championship",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data.Age,data.Outcome).plot(kind=\"bar\", figsize=(20,10));\n",
    "plt.title('Diabetes frequency by Age');\n",
    "plt.legend(['No Diabetes','Diabetic']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a correlation matrix\n",
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let' make our correlation more communicating\n",
    "corr_matrix = data.corr()\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax = sns.heatmap(corr_matrix, annot=True, linewidths=0.5, fmt=\".2f\", cmap=\"YlGnBu\");\n",
    "ax.set(title='Correlation between different labels');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-impossible",
   "metadata": {},
   "source": [
    "## Choosing a model\n",
    "\n",
    "Try different Machine Learning models\n",
    "* RandomForestClassifier\n",
    "* LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-actor",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"LinearSVC\": SVC(),\n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "    \"KNearestNeighbors\": KNeighborsClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model Precision, Recall, F1 scores\n",
    "def eval_prediction(y_test, y_preds):\n",
    "   return {\"Accuracy\": round(accuracy_score(y_test, y_preds),2),\n",
    "           \"Precision\": round(precision_score(y_test, y_preds),2),\n",
    "           \"Recall\": round(recall_score(y_test, y_preds),2),\n",
    "           \"F1\": round(f1_score(y_test, y_preds),2)}\n",
    "\n",
    "# Fit and score model\n",
    "def fit_and_score(models, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "        Evaluates different machine learning models.\n",
    "        \n",
    "        model: A dict of different sklearn models\n",
    "        X_train: Training data (no label)\n",
    "        X_test: Testing data (no labels)\n",
    "        y_train: Training label\n",
    "        y_test: Testing Label\n",
    "    \"\"\"\n",
    "    model_scores = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        model_scores[name] = round(model.score(X_test, y_test)*100,2)\n",
    "        \n",
    "    return model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-corner",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split data into features and label\n",
    "X = data.drop('Outcome', axis=1)\n",
    "y = data['Outcome']\n",
    "\n",
    "\n",
    "# Split data into train and test splits\n",
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
    "model_scores = fit_and_score(models,X_train, X_test, y_train, y_test)\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experienced-helen",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-philosophy",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparison = pd.DataFrame(model_scores, index=['accuracy'])\n",
    "model_comparison.T.plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-geology",
   "metadata": {},
   "source": [
    "**Note**: A models default accuracy is not always true, so we are going to evaluate it the more to increase accuracy\n",
    "\n",
    "**What I'm going to look into:**\n",
    "1. Hyperparameter Tuning\n",
    "2. Feature Importance\n",
    "3. Confusion matrix\n",
    "4. Cross validation\n",
    "5. Precision\n",
    "6. Recall\n",
    "7. F1 score\n",
    "8. Classification Report\n",
    "9. ROC curve\n",
    "10. AUC curve\n",
    "\n",
    "### Hyperparameter Tuning (By Hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-distributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune KNN\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "# Create a list of different values for n_neighbors\n",
    "neighbors = range(1, 21)\n",
    "\n",
    "# Instatiate KNN\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Loop through neigbors\n",
    "for i in neighbors:\n",
    "    knn.set_params(n_neighbors=i)\n",
    "    \n",
    "    # Fit the model\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Update Training scores\n",
    "    train_scores.append(knn.score(X_train, y_train))\n",
    "    \n",
    "    # Update Test scores\n",
    "    test_scores.append(knn.score(X_test,y_test))\n",
    "\n",
    "# train_scores, test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(neighbors, train_scores, label=\"Train Scores\");\n",
    "plt.plot(neighbors, test_scores, label=\"Test Scores\");\n",
    "plt.xlabel(\"Number of Neighbors\")\n",
    "plt.ylabel(\"Model Score\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(f\"The maximum Test score is {max(test_scores)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-patent",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning with RandomizedSearchCV\n",
    "\n",
    "I'm going to tune:\n",
    "* LogisticRegression \n",
    "* RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-playing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "logistic_grid = {\n",
    "    \"C\" : np.logspace(-4, 4, 50),\n",
    "    \"solver\":['liblinear'],\n",
    "}\n",
    "\n",
    "# Create Hyperparameter grid for RandomforestClassifier\n",
    "rs_grid ={\n",
    "    \"n_estimators\": np.arange(10,500, 50),\n",
    "    \"max_depth\": [None, 3,5,10],\n",
    "    \"min_samples_split\": np.arange(2,40,2),\n",
    "    \"min_samples_leaf\": np.arange(1,25,2)\n",
    "}\n",
    "\n",
    "# Now Let's tune LogisticRegression using RandomizedSearchCV\n",
    "logistic_rs_model = RandomizedSearchCV(estimator=LogisticRegression(), \n",
    "                              param_distributions=logistic_grid, \n",
    "                              cv=5, verbose=2, n_iter=20)\n",
    "\n",
    "# Fit model for Logistic Regression\n",
    "logistic_rs_model.fit(X_train, y_train);\n",
    "logistic_rs_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-focus",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_rs_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-saturday",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-closure",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_rs_model = RandomizedSearchCV(estimator=RandomForestClassifier(), param_distributions=rs_grid, \n",
    "                                 cv=5, n_iter=20, verbose=2)\n",
    "# Fit the RandomForestClassifier\n",
    "rf_rs_model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-scheduling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the RandomForestClassifier\n",
    "rf_rs_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-young",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning using the GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-munich",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "logistic_grid = {\n",
    "    \"C\" : np.logspace(-4, 4, 50),\n",
    "    \"solver\":['liblinear'],\n",
    "}\n",
    "\n",
    "# Create Hyperparameter grid for RandomforestClassifier\n",
    "rs_grid ={\n",
    "    \"n_estimators\": np.arange(10,200, 50),\n",
    "    \"max_depth\": [None, 3,5,10],\n",
    "    \"min_samples_split\": np.arange(2,10,2),\n",
    "    \"min_samples_leaf\": np.arange(1,10,2)\n",
    "}\n",
    "\n",
    "logistic_gs_model = GridSearchCV(estimator=LogisticRegression(), param_grid=logistic_grid, cv=5,verbose=2)\n",
    "\n",
    "# Fit the Logistic Regression Model\n",
    "logistic_gs_model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_gs_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-timing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameter tuning using of RandomForestClassifier using GridSearchCV\n",
    "rf_gs_model = GridSearchCV(estimator=RandomForestClassifier(), param_grid=rs_grid,cv=5, verbose=2)\n",
    "rf_gs_model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-montana",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_gs_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-forestry",
   "metadata": {},
   "source": [
    "## Evaluating Our Tuned model Beyond Accuracy\n",
    "* ROC curve\n",
    "* Confusion matrix\n",
    "* Classification Report\n",
    "* Precision\n",
    "* Recall\n",
    "* F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-storm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Prediction with tuned model\n",
    "logistic_preds = logistic_rs_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "plot_roc_curve(logistic_rs_model,X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, logistic_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-balloon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix using seaborn\n",
    "sns.set(font_scale=0.5)\n",
    "def plot_conf_matrix(y_test, y_preds):\n",
    "    \"\"\"\n",
    "        Plots a confusion matrix using seaborn's heatmap\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10,5))\n",
    "    ax = sns.heatmap(confusion_matrix(y_test,y_preds), annot=True, cbar = False)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\");\n",
    "    \n",
    "plot_conf_matrix(y_test, logistic_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "from sklean.metrics import classification_report\n",
    "classification_report(y_test, logistic_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation score\n",
    "def cross_val(model, scoring_param):\n",
    "    \"\"\"\n",
    "        Returns cross validated score of a model according to the scoring parameter passed\n",
    "        scoring_param: Cross validation scoring parameter\n",
    "        model: working estimator\n",
    "    \"\"\"\n",
    "    score = cross_val_score(model,X, y, cv=5, scoring=scoring_param)\n",
    "    try:\n",
    "        return f\"The {scoring_param} score is: {score*100:.2f}\"\n",
    "    except NameError:\n",
    "        print (\"Invalid scoring parameter passed\")\n",
    "    except:\n",
    "        print (\"Something went wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-gallery",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "y_probs = clf.predict_proba(X_test)\n",
    "# y_probs\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_preds = clf.predict(X_test)\n",
    "confusion_matrix(y_test, y_preds)\n",
    "# roc_curve(y_test, y_preds)\n",
    "pd.crosstab(y_test, y_preds, rownames=['Actual label'], colnames=['Predicted label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-perth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameter Tuning using RandomizedSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "grid ={\n",
    "    'n_estimators': [100,200,500,1200],\n",
    "    'max_depth': [2,3],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'min_samples_leaf':[2,5,7],\n",
    "    'min_samples_split': [2,4]\n",
    "}\n",
    "\n",
    "rs = RandomizedSearchCV(estimator=clf, param_distributions=grid, n_iter=5, cv=5, verbose=2)\n",
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.predict(X_test)\n",
    "rs.score(X_test,y_test)*100, clf.score(X_test, y_test)*100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
